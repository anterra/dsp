[Think Stats Chapter 4 Exercise 2](http://greenteapress.com/thinkstats2/html/thinkstats2005.html#toc41) (a random distribution)

## Exercise 4.2

> This questions asks you to examine the function that produces random numbers. Is it really random? A good way to test that is to examine the pmf and cdf of the list of random numbers and visualize the distribution. If you're not sure what pmf is, read more about it in Chapter 3.

> The numbers generated by random.random are supposed to be
uniform between 0 and 1; that is, every value in the range should have the
same probability.
Generate 1000 numbers from random.random and plot their PMF and CDF.
Is the distribution uniform?

The numpy built-in function random.random([size]) generates a random float in the half-open interval of [0.0, 1.0).
It, like all algorithms used to generate "random" numbers, is considered psuedo-random. This has to do with the defition of 'random' -- random does not mean a different number every time, but rather means a number that cannot be predicted logically. Any algorithm-generated number can be predicted since algorithms are deterministic, and hence it is not truly random.

This doesn't, however, mean it can't do a good job of generating a uniform distribution of random numbers and i.e. selecting them effectively "randomly". To investigate the randomness of the np.random.random function, as prompted, I generated an array of 1000 "random" numbers as follows:  

```
import numpy as np
numbers = np.random.random(1000)
```
Then, plotted its probability mass function (PMF) with the following code:
```
pmf = thinkstats2.Pmf(numbers)
thinkplot.Pmf(pmf, linewidth=0.1)
thinkplot.Config(xlabel="Random Number", ylabel="PMF")
```
The first time I executed the code, I didn't think to include the specification of "linewidth=0.1", and my plot was just a solid block of color. This was because each line's width was so large it overlapped every other line, and no meaningful results could hence be seen. Decreasing the line width as the author did in the solution then yielded the following plot: 

![pmf_1000](https://github.com/anterra/ThinkStats2/blob/master/pmf_4.2_1000.png)

At first glance, the distribution does not look completely uniform, as there are clusters of higher density around certain values and gaps around others. Interestingly though, it should be noted that the height of every bar is the same. This indicates an equal probability of each value in the array having been chosen, and specifically that each value was chosen only once -- this being confirmed by the fact that the maximum height of the bars, or probability of being selected, was set at 0.001, or 0.1% chance, i.e. 1 in 1000 (our sample size)  I created and consulted the cumulative distribution function (CDF) for this array which yieled the following: 

```
cdf = thinkstats2.Cdf(numbers)
thinkplot.Cdf(cdf)
thinkplot.Config(xlabel="Random Number", ylabel="CDF")

numbers = np.random.random(10000)
```
![cdf_1000](https://github.com/anterra/ThinkStats2/blob/master/cdf_4.2_1000.png)

The CDF above can be seen to be pretty close to uniform, with slight deviations from linear. So, why the gaps in the PMF and the slight CDF variance? My theory was that the percieved non-uniformity was due not to a lack of randomness on the part of the random number generating method, but simply due to a small sample size. It is not a lack of equal likelihood that some numbers would be chosen and not others, but only that within 1000 selections of numbers, some happened to get chosen and some did not, and that with a large enough sample size, one would see uniformity. 

To test this hypothesis, I ran all of the above code again but with a generated np.random.random array size of 10000. I then decreased the PMF line width to 0.05 to once again avoid overlap so meaningful results could be seen. I ended up with the following plot: 

![pmf_10000](https://github.com/anterra/ThinkStats2/blob/master/pmf_10000_2.png)

Here one observes a much more uniform distribution of numbers, and here also the maximum probability/bar height has been adjusted to 0.0001, or 0.01% = 1 in 10000. In verifying with the CDF: 

![cdf_10000](https://github.com/anterra/ThinkStats2/blob/master/cdf_4.2_10000.png)

Indeed one sees a virtually perfect straight line. This seems to indicate to me that with enough repeated trials, the np.random.random method does yield a uniform distribution of numbers, and it was only the relatively small selection of numbers before that demonstrated percieved non-uniformity. It at least seems sufficient to reject the null hypothesis that the np.random.random method favors some numbers and avoids certain others as the first PMF of 1000 numbers may look like. As in any event in real-life, only in large enough samples do outcomes even out to their probablistic outcomes. 

Still, it should be stressed that this method is still an algorithm, and hence produces only pseudo-random numbers as described above. 
